{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3183cb-0584-4081-8d94-97fd08a1bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef509add-6121-4429-87ad-22c3efe50948",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5231130c-5827-417b-bdab-5d764161814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "N_QUERYS = 10\n",
    "HOP_SIZE = 512\n",
    "OFFSET = 0\n",
    "DURATION = 600\n",
    "THRESHOLD = 0\n",
    "BAND_SIZE = 10\n",
    "PERMUTATIONS = 300\n",
    "SEED = 26\n",
    "MOD = 1423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5fba0f1-d954-4308-a62c-d2203c6044d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "data_folder = Path(\"./mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424ff3bc-42d6-4351-ab5c-3a0c4246a1ac",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d7a99dc-86b1-4652-88d3-ad3c432499f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.Spero che siate aggiornati sulla stagione UK???? ￼￼￼￼￼\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_peaks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"Plots the spectrogram and peaks \n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_peaks(audio, offset, duration, hop_size):\n",
    "    \"\"\"Load the tracks and peaks of an audio.\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        offset (float): start reading after this time (in seconds)\n",
    "        duration (float): only load up to this much audio (in seconds)\n",
    "        hop_size (int): the hop_length\n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), \n",
    "        a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, offset=offset, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1de84-f7d3-4ac2-9d99-56e7e82434b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Minhash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae1587-aa8a-4cd5-ae87-75e7068102b6",
   "metadata": {},
   "source": [
    "## Building the signatures of the tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95f291-cfd2-4ea2-bd31-f00ad2c6c3fe",
   "metadata": {},
   "source": [
    "Computing longest track duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae09c68e-c93d-4903-a413-f14dd9508767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the track duration from the first element of the dataset\n",
    "tracks = sorted(data_folder.glob(\"*/*/*.wav\"), key=os.path.getsize) # sorting tracks by size\n",
    "_, sr, onset_env, _ = load_audio_peaks(tracks[-1], OFFSET, DURATION, HOP_SIZE) #input longest track\n",
    "TrackDuration = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr, hop_length=HOP_SIZE) #max size track duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c29ca4-7c28-4f34-b4f7-0d936ef2eea2",
   "metadata": {},
   "source": [
    "The method used to compute the minhash value of each track is:\n",
    "1) Extraxt audio peaks\n",
    "2) A  ShingleArray is build, it represents the track only with it's peaks:\n",
    "    - The track is an array of zeros and ones \n",
    "    - Each array element represents a given moment in time\n",
    "    - Ones represent peaks, and so the elements of the array are all zeros except at the moment in which a peak was computed\n",
    "3) The elements of the array are randomly permuted #PERMUTATOINS times; the seed of the permuting algorithm is initialized for each track\n",
    "4) At each permutation the index of the first non zero element is recorded in the SignatureArray of the track to guarantee conformity\n",
    "5) Each track is assigned an ID, the correspondance ID - track_path is recorded in a dictionary; this dictionay is dumped to a file to be recalled without re-running the code \n",
    "6) The ShingleArray and the SignatureArray are stored in a the ShingleMatrix and the SignatureMatrix with the columns corresponding to the track ID; this matrixes are dumped to a file to be recalled without re-running the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c683f488-1bad-4997-8d14-f8fa2a2ddcdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#redefining tracks to re-start from the first element of tracks generator\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")\n",
    "\n",
    "#dictionary to associate track ID row with it's path\n",
    "IDofTrack = dict()\n",
    "\n",
    "#defining the SignatureArray\n",
    "SignatureMatrix = np.empty((PERMUTATIONS, N_TRACKS), dtype=int) #row index: permutation number, column index: ID\n",
    "ShingleMatrix = np.empty((len(TrackDuration), N_TRACKS), dtype=int) #row: time instant, column index: ID\n",
    "\n",
    "#buiding the shingle matrix and the first row of the signature matrix\n",
    "for ID, audio in enumerate(tqdm(tracks, total=N_TRACKS)):\n",
    "    AudioPath = '/'.join(os.path.abspath(audio).split('/')[-3:]) #formatting the path to have only essential info\n",
    "    IDofTrack[ID] = AudioPath\n",
    "    _, _, _, peaks = load_audio_peaks(audio, OFFSET, DURATION, HOP_SIZE) #computing peak indexes\n",
    "    \n",
    "    #buiding a Shingle array\n",
    "    ShingleArray =  np.zeros(len(TrackDuration), dtype=int)\n",
    "    for PeakIdx in peaks:\n",
    "        ShingleArray[PeakIdx] = 1\n",
    "    ShingleMatrix[:, ID] = ShingleArray\n",
    "    \n",
    "    #permuting the shingle array and recording it's the first non null element in the SignatureArray\n",
    "    #initializing the random number generator to obtain consistent permutations across all tracks\n",
    "    rng = np.random.default_rng(SEED) \n",
    "    for i in range(PERMUTATIONS):\n",
    "        ShuffledShingleArray = rng.permutation(ShingleArray)\n",
    "        SignatureMatrix[i][ID] = ShuffledShingleArray.argmax()\n",
    "        \n",
    "#storing the computed matrixes\n",
    "with open('ShingleMatrix', 'wb') as f:\n",
    "    pickle.dump(ShingleMatrix, f)\n",
    "with open('SignatureMatrix', 'wb') as f:\n",
    "    pickle.dump(SignatureMatrix, f)\n",
    "with open('IDofTrack', 'wb') as f:\n",
    "    pickle.dump(IDofTrack, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af3da1-92ab-4fcc-ad7a-ea6df68d7c27",
   "metadata": {},
   "source": [
    "Importing SignatureMatrix and IDofTracks instead of running minhash code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ecbe50-fa4a-489d-9152-d1cbd812ef4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_SignatureMatrix = open('SignatureMatrix', \"rb\")\n",
    "SignatureMatrix = pickle.load(pickle_SignatureMatrix)\n",
    "\n",
    "pickle_IDofTrack = open('IDofTrack', \"rb\")\n",
    "IDofTrack = pickle.load(pickle_IDofTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d076f1d-a6e6-46da-9ea7-85399c312974",
   "metadata": {},
   "source": [
    "## Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10035cd-0227-40ba-89df-353565f68443",
   "metadata": {},
   "source": [
    "The algorithm below is a basic hashing function. \n",
    "1) The elements of the input array are multiplied to a random number\n",
    "2) They are then summed\n",
    "3) The output is the reminder of the division by MOD\n",
    "\n",
    "MOD is the closest prime number to N_TRACKS, this condition limits random collisions, i.e. the hashed elements will be almost equally distributed through the #MOD bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6753b5fc-b887-413f-b3e3-ecbbdc522306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HashFunction(Shingle):\n",
    "    np.random.seed(SEED)\n",
    "    c = np.array([np.random.randint(MOD) for i in range(BAND_SIZE)])\n",
    "    return np.multiply(Shingle, c).sum() % MOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d650e-c820-4de6-a6d5-f2f3381f1ba6",
   "metadata": {},
   "source": [
    "A bag method is used for bucketing:\n",
    "1) The SignatureArray of each track is divided in to arrays of lenght BAND_SIZE; we refer to those array as tokens, a track is now represented through the set of it's tokens\n",
    "2) The hash values of this tokens are computed through the hash function\n",
    "3) A dictionary is build:\n",
    "    - it's keys are the hash value of a given token\n",
    "    - the values of the keys are the buckets containing the track ID's in which have the corresponding token\n",
    "    - this values are counters that store the number of occurences of the token of each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2ecb974-3e13-470c-b22d-d56fd3cfbb20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def BucketingShingles():\n",
    "    ShingleBuckets = defaultdict(Counter)\n",
    "    #hashing the audio track using as keys it's signatures grouped in bands of size BAND_SIZE\n",
    "    for ID in range(N_TRACKS):\n",
    "        for i in range(0, PERMUTATIONS, BAND_SIZE):   \n",
    "            Shingle = SignatureMatrix[:, ID][i:(i+BAND_SIZE)]\n",
    "            BucketKey = HashFunction(Shingle)\n",
    "            ShingleBuckets[str(BucketKey)][ID] +=1\n",
    "    return(ShingleBuckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b9d69b-1c4e-4028-a35f-60b7abf0bd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a1ed3-beef-40ba-bdf3-923d1ec59303",
   "metadata": {},
   "source": [
    "The minhash method was used to process the querys in the same manner as the dataset.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "For each token of the query the corresponding bucket is retrived. It is remainded that this bucket contains the tracks that contained the token, associated with the number of occurences of that token.\\\n",
    "A TrackSimilarities counter is now used to store the number of occurences of the tracks of all the query tokens. This method de facto groups the tracks and it's number of occurences contained in all the buckets to which the query belongs.\\\n",
    "The tracks with most occurances are then retrieved from the TrackSimilarities dictionary to make a comparision of the respective SignatureArrays with the query. The number of similarities divided by the number of array elements will be the Jaccard Similiraity of the tracks.\n",
    "\n",
    "As defined in Mining of Massive Datasets by Jure Leskovec the threshold $T$ is the value of similarity $JS$ at which the probability of becoming a candidate is $1/2$. Conforming to the book notation:\n",
    "- $b$ = `#BANDS`\n",
    "- $r$ = `BAND_SIZE`\n",
    "\n",
    "with `#BANDS = PERMUTATIONS / BAND_SIZE` that is:\n",
    "- $b$ = `PERMUTATIONS` / $r$\n",
    "\n",
    "An approximation to the threshold is $(\\frac{1}{r})^{1 / b}$.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "The output of the following function `EvaluateQuerys()` code cell prints:\n",
    "- the query track itself. This was checked by a direct audio comparison of the audio of the query and the best match\n",
    "- the second best match with it's Jaccard Similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f5d933-8efb-4b02-bf80-a226dd65765b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def EvaluateQuerys():\n",
    "    #defing path variables\n",
    "    query_folder = Path(\"./querys\")\n",
    "    querys = sorted(query_folder.glob(\"*.wav\"), key=os.path.getmtime)\n",
    "\n",
    "    #buiding the shingle matrix and the first row of the signature matrix\n",
    "    for ID, audio in enumerate(querys):\n",
    "        # if ID < 1:\n",
    "        AudioPath = os.path.abspath(audio).split('/')[-1] #formatting the path to have only essential info\n",
    "        _, _, _, peaks = load_audio_peaks(audio, OFFSET, DURATION, HOP_SIZE) #computing peack indexes\n",
    "\n",
    "        #buiding a Shingle array\n",
    "        ShingleArray =  np.zeros(len(TrackDuration), dtype=int)\n",
    "        for PeakIdx in peaks:\n",
    "          ShingleArray[PeakIdx] = 1\n",
    "\n",
    "        #defining the SignatureArray\n",
    "        SignatureArray = np.empty(PERMUTATIONS, dtype=int)\n",
    "\n",
    "        #permuting the shingle array and recording it's the first non null element in the SignatureArray\n",
    "        #initializing the random number generator to obtain consistent permutations across all tracks\n",
    "        rng = np.random.default_rng(SEED) \n",
    "        for i in range(PERMUTATIONS):\n",
    "            ShuffledShingleArray = rng.permutation(ShingleArray)\n",
    "            SignatureArray[i] = ShuffledShingleArray.argmax()\n",
    "\n",
    "        #hashing the audio track using as keys it's signatures grouped in bands of size BAND_SIZE\n",
    "        #storing the hashes in a list to retrieve the buckets to which the query belongs\n",
    "        QueryBuckets = np.empty(0, dtype=int)\n",
    "        for i in range(0, PERMUTATIONS, BAND_SIZE):\n",
    "            Shingle = SignatureArray[i:(i+BAND_SIZE)]\n",
    "            BucketKey = HashFunction(Shingle)\n",
    "            QueryBuckets = np.append(QueryBuckets, BucketKey)\n",
    "\n",
    "        #interection of buckets to which the query belongs\n",
    "        # IntersectionElements = [*set.intersection(*[ShingleBuckets[key] for key in QueryBuckets[:3]])]\n",
    "        TrackSimilarities = Counter()\n",
    "        for q in QueryBuckets:\n",
    "            TrackSimilarities.update(ShingleBuckets[str(q)])\n",
    "\n",
    "        #track is...\n",
    "        #print bucket elements to which the query belongs\n",
    "        QueryName = AudioPath.split('.')[0]\n",
    "        # for element in IDofTrack[TrackSimilarities.most_common()[0][0]]:\n",
    "        track = IDofTrack[TrackSimilarities.most_common()[0][0]]\n",
    "        #formatting\n",
    "        Title = track.split('/')[-1][:-4].replace('_', ' ')\n",
    "        Title = re.sub(r'[\\d^-]', '', Title)\n",
    "        Album = track.split('/')[1].split('_')\n",
    "        Album = ' '.join([name.capitalize() for name in Album])\n",
    "        Author = track.split('/')[0].split('_')\n",
    "        Author = ' '.join([name.capitalize() for name in Author])\n",
    "        QueryNameAlligned = str.center(AudioPath.split('.')[0] + ':', (13 + len(QueryName)))\n",
    "        print(f'{QueryNameAlligned}{Author} - {Title} ({Album})')\n",
    "\n",
    "        #most similar track has Jaccard similarity\n",
    "        IDFirstSimilarity = TrackSimilarities.most_common()[0][0]\n",
    "        IDSecondSimilarity = TrackSimilarities.most_common()[1][0]\n",
    "\n",
    "        track = IDofTrack[TrackSimilarities.most_common()[1][0]]\n",
    "        #formatting\n",
    "        Title = track.split('/')[-1][:-4].replace('_', ' ')\n",
    "        Title = re.sub(r'[\\d^-]', '', Title)\n",
    "        Album = track.split('/')[1].split('_')\n",
    "        Album = ' '.join([name.capitalize() for name in Album])\n",
    "        Author = track.split('/')[0].split('_')\n",
    "        Author = ' '.join([name.capitalize() for name in Author])\n",
    "\n",
    "        JaccardSimilarity = sum(SignatureMatrix[:, IDFirstSimilarity] == \\\n",
    "                                SignatureMatrix[:, IDSecondSimilarity]) / PERMUTATIONS\n",
    "        print(f'{QueryName} best match: {Author} - {Title} ({Album}) with JS of {JaccardSimilarity: .3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b40a2-0d4b-4a22-9b99-60b98906bdd2",
   "metadata": {},
   "source": [
    "In the first example the parameers used are:\n",
    "- `PERMUTATIONS` = 300\n",
    "- `BAND_SIZE` = 3\n",
    "\n",
    "and so:\\\n",
    "$b = 300 / 3 = 100$ \\\n",
    "$T = 0.215$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ee00a6-3880-4999-bc30-3fc1ec8fc9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      track1:      Aerosmith - Dream On (Aerosmith)\n",
      "track1 best match: Beatles - Baby s In Black (Beatles For Sale) with JS of  0.023\n",
      "\n",
      "      track2:      Queen - I Want To Break Free (The Works)\n",
      "track2 best match: Suzanne Vega - Small Blue Thing (Suzanne Vega) with JS of  0.030\n",
      "\n",
      "      track3:      U2 - October (October)\n",
      "track3 best match: Metallica - Bleeding Me (Load) with JS of  0.010\n",
      "\n",
      "      track4:      Beatles - ObLaDi ObLaDa (The White Album Disc 1)\n",
      "track4 best match: U2 - Love Is Blindness (Achtung Baby) with JS of  0.023\n",
      "\n",
      "      track5:      Radiohead - Karma Police (Ok Computer)\n",
      "track5 best match: Green Day - Dominated Love Slave (Kerplunk) with JS of  0.007\n",
      "\n",
      "      track7:      Fleetwood Mac - Go Your Own Way (Rumours)\n",
      "track7 best match: Green Day - Jinx (Nimrod) with JS of  0.017\n",
      "\n",
      "      track8:      Green Day - American Idiot (American Idiot)\n",
      "track8 best match: Radiohead - I Might Be Wrong (Amnesiac) with JS of  0.013\n",
      "\n",
      "      track6:      Led Zeppelin - Heartbreaker (Led Zeppelin Ii)\n",
      "track6 best match: Depeche Mode - A question of lust (Black Celebration) with JS of  0.043\n",
      "\n",
      "      track9:      Depeche Mode - Somebody (Some Great Reward)\n",
      "track9 best match: Radiohead - Idioteque (Kid A) with JS of  0.010\n",
      "\n",
      "      track10:      Steely Dan - Black Friday (Katy Lied)\n",
      "track10 best match: Green Day - Walking Contradiction (Insomniac) with JS of  0.017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BAND_SIZE = 3\n",
    "PERMUTATIONS = 300\n",
    "ShingleBuckets = BucketingShingles()\n",
    "EvaluateQuerys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba10c2-cf3d-49de-89a0-f111eba6e07f",
   "metadata": {},
   "source": [
    "Now the parameers are:\n",
    "- `PERMUTATIONS` = 300\n",
    "- `BAND_SIZE` = 10\n",
    "\n",
    "and so:\\\n",
    "$b = 300 / 10 = 30$ \\\n",
    "$T = 0.712$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13fdd25f-976a-4382-a222-cc869ace0de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      track1:      Aerosmith - Dream On (Aerosmith)\n",
      "track1 best match: Garth Brooks - I ve Got A Good Thing Going (Garth Brooks The Limited Series ) with JS of  0.023\n",
      "\n",
      "      track2:      Queen - I Want To Break Free (The Works)\n",
      "track2 best match: U2 - Running to Stand Still (The Joshua Tree) with JS of  0.027\n",
      "\n",
      "      track3:      U2 - October (October)\n",
      "track3 best match: Dave Matthews Band - Don t Drink the Water (Before These Crowded Streets) with JS of  0.000\n",
      "\n",
      "      track4:      Beatles - ObLaDi ObLaDa (The White Album Disc 1)\n",
      "track4 best match: Fleetwood Mac - Over My Head (Fleetwood Mac) with JS of  0.020\n",
      "\n",
      "      track5:      Radiohead - Karma Police (Ok Computer)\n",
      "track5 best match: Fleetwood Mac - Walk a Thin Line (Tusk) with JS of  0.013\n",
      "\n",
      "      track7:      Fleetwood Mac - Go Your Own Way (Rumours)\n",
      "track7 best match: Metallica - Metal Militia (Kill Em All) with JS of  0.017\n",
      "\n",
      "      track8:      Green Day - American Idiot (American Idiot)\n",
      "track8 best match: Cure - The Snakepit (Kiss Me Kiss Me Kiss Me) with JS of  0.000\n",
      "\n",
      "      track6:      Led Zeppelin - Heartbreaker (Led Zeppelin Ii)\n",
      "track6 best match: Metallica - Motorbreath (Kill Em All) with JS of  0.017\n",
      "\n",
      "      track9:      Depeche Mode - Somebody (Some Great Reward)\n",
      "track9 best match: Depeche Mode - New dress (Black Celebration) with JS of  0.017\n",
      "\n",
      "      track10:      Steely Dan - Black Friday (Katy Lied)\n",
      "track10 best match: Garth Brooks - Every Now And Then (The Chase) with JS of  0.033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BAND_SIZE = 10\n",
    "PERMUTATIONS = 300\n",
    "ShingleBuckets = BucketingShingles()\n",
    "EvaluateQuerys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a66b7ce-5208-4dbf-b48f-81ea66015353",
   "metadata": {},
   "source": [
    "Now the parameers are:\n",
    "- `PERMUTATIONS` = 150\n",
    "- `BAND_SIZE` = 5\n",
    "\n",
    "and so:\\\n",
    "$b = 150 / 5 = 30$ \\\n",
    "$T = 0.507$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0df80f1c-4fad-4a6f-94e0-f74d35ba485b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      track1:      Aerosmith - Dream On (Aerosmith)\n",
      "track1 best match: Suzanne Vega - Song Of Sand (99 9 F ) with JS of  0.020\n",
      "\n",
      "      track2:      Queen - I Want To Break Free (The Works)\n",
      "track2 best match: Madonna - Bye Bye Baby (Erotica) with JS of  0.073\n",
      "\n",
      "      track3:      U2 - October (October)\n",
      "track3 best match: Green Day - King For A Day (Nimrod) with JS of  0.013\n",
      "\n",
      "      track4:      Beatles - ObLaDi ObLaDa (The White Album Disc 1)\n",
      "track4 best match: Radiohead - I Will (Hail To The Theif) with JS of  0.000\n",
      "\n",
      "      track5:      Radiohead - Karma Police (Ok Computer)\n",
      "track5 best match: Queen - Keep Passing The Open Windows (The Works) with JS of  0.013\n",
      "\n",
      "      track7:      Fleetwood Mac - Go Your Own Way (Rumours)\n",
      "track7 best match: Radiohead - A Wolf at the Door (Hail To The Theif) with JS of  0.027\n",
      "\n",
      "      track8:      Green Day - American Idiot (American Idiot)\n",
      "track8 best match: Cure - Bare (Wild Mood Swings) with JS of  0.013\n",
      "\n",
      "      track6:      Led Zeppelin - Heartbreaker (Led Zeppelin Ii)\n",
      "track6 best match: Metallica - Welcome Home Sanitarium  (Master Of Puppets) with JS of  0.027\n",
      "\n",
      "      track9:      Depeche Mode - Somebody (Some Great Reward)\n",
      "track9 best match: U2 - Like A Song  (War) with JS of  0.033\n",
      "\n",
      "      track10:      Steely Dan - Black Friday (Katy Lied)\n",
      "track10 best match: Tori Amos - Cornflake Girl (Under The Pink) with JS of  0.040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BAND_SIZE = 5\n",
    "PERMUTATIONS = 150\n",
    "SignatureMatrix = SignatureMatrix[:150]\n",
    "ShingleBuckets = BucketingShingles()\n",
    "EvaluateQuerys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae5035-5134-49cf-a132-aca5b9044e0d",
   "metadata": {},
   "source": [
    "Different combinations of the band size and the number of permutations gave different similarities of the querys but a significant variation of the $JS$ is not observed. \\\n",
    "The result could be imporved with:\n",
    "- expanding the dataset, this would allow to have more shingles and more probability of similarities between them\n",
    "- adding some \"noise\" to the peaks, de facto \"spreading\" the peaks over more array elements so to loosen the constrain that the peaks of the tracks should precisely match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
